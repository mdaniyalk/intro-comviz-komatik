{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "AuW-xg_bTsaF",
      "metadata": {
        "id": "AuW-xg_bTsaF"
      },
      "source": [
        "# Practice Lab: Chest Cancer Detection\n",
        "\n",
        "Welcome to the Practice Lab! You will be using the `Chest CT-Scan Dataset` from [kaggle](https://www.kaggle.com/datasets/mohamedhanyyy/chest-ctscan-images) dataset to train a model that can detect chest cancer from ct-scan images. For this, you will use `Functional API` and `Transfer Learning` using base model of `MobileNetv2` to train your dataset.\n",
        "\n",
        "Let's get started!"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "e40dc6e7",
      "metadata": {},
      "source": [
        "Note: \n",
        "1. The dataset is slightly modified to fit this practice lab\n",
        "2. Try to use data augmentations using tools like tensforlow ImageDataGenerator\n",
        "3. Try to modify the networks to your own preference\n",
        "4. You can also use another pre-trained base model from [Tensforlow Model Hub](https://tfhub.dev/) or [Model Zoo](https://modelzoo.co/framework/tensorflow)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dn-6c02VmqiN",
      "metadata": {
        "id": "dn-6c02VmqiN",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Import the necessary libraries\n",
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split \n",
        "from random import randint\n",
        "import cv2"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "bLTQd84RUs1j",
      "metadata": {
        "id": "bLTQd84RUs1j"
      },
      "source": [
        "Download the dataset by running the cell below. \n",
        "\n",
        "Note that the `zip` file that contains the images is unzipped under the `/tmp` directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3sd9dQWa23aj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sd9dQWa23aj",
        "lines_to_next_cell": 2,
        "outputId": "5cae5a66-75c4-4aa0-b938-d1c5e0a3d626",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# If the URL doesn't work, visit https://drive.google.com/uc?id=1CRuANxqfiSqUAGxlqoxkZWjnINHg5fUC\n",
        "# And download manually\n",
        "\n",
        "!gdown \"1CRuANxqfiSqUAGxlqoxkZWjnINHg5fUC&confirm=t\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "226b2a91",
      "metadata": {},
      "outputs": [],
      "source": [
        "!unzip chest_ct-scan.zip"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "e_HsUV9WVJHL",
      "metadata": {
        "id": "e_HsUV9WVJHL"
      },
      "source": [
        "Now the images are stored within the `/chest_ct-scan` directory. The directory is splitted to train, valid, test. \n",
        "There is a subdirectory for each class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DM851ZmN28J3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DM851ZmN28J3",
        "outputId": "136ecb45-41dc-4e81-c0dd-752f86e71cfa",
        "tags": []
      },
      "outputs": [],
      "source": [
        "source_path = '/content/chest_ct-scan'\n",
        "\n",
        "# Deletes corrupt images files\n",
        "class_names = ['adenocarcinoma', 'squamous-cell-carcinoma', 'large-cell-carcinoma', 'normal']\n",
        "\n",
        "for _class in class_names:\n",
        "  folder_path = os.path.join(source_path, _class)\n",
        "  for img_file in os.listdir(folder_path):\n",
        "    path = os.path.join(folder_path, img_file)\n",
        "    try:\n",
        "      image=tf.keras.preprocessing.image.load_img(path)\n",
        "    except:\n",
        "      print(f'Removing {img_file} in {_class}')\n",
        "      os.remove(path)\n",
        "\n",
        "# os.listdir returns a list containing all files under the given path\n",
        "for _class in class_names:\n",
        "  print(f\"There are {len(os.listdir(os.path.join(source_path, _class)))} images of {_class}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86a2c8b7",
      "metadata": {},
      "outputs": [],
      "source": [
        "def preview_sample(SOURCE_DIR, NUM_OF_IMGS):\n",
        "  \"\"\"\n",
        "  Preview sample images from directories\n",
        "  \n",
        "  Args:\n",
        "    SOURCE_DIR (string): directory path containing the images\n",
        "    NUM_OF_IMGS (int): number sample of images to preview\n",
        "    \n",
        "  Returns:\n",
        "    None\n",
        "  \"\"\"\n",
        "  for i in range(NUM_OF_IMGS):\n",
        "    img_class = random.choice(['adenocarcinoma', 'squamous-cell-carcinoma', 'large-cell-carcinoma', 'normal'])\n",
        "    folder_path = os.path.join(SOURCE_DIR, img_class)\n",
        "    img_path = os.listdir(folder_path)\n",
        "    img = cv2.imread(os.path.join(folder_path, random.choice(img_path)))\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "87dc7f7a",
      "metadata": {},
      "source": [
        "Displaying random sample images from dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6088a3d",
      "metadata": {},
      "outputs": [],
      "source": [
        "img_path = preview_sample(source_path, 3)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "ce0f7350",
      "metadata": {},
      "source": [
        "Read Images and it's labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e3d2701",
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_dataset(SOURCE_DIR, CLASS_NAME, TARGET_SIZE):\n",
        "  \"\"\"\n",
        "  Load images and labels from directories\n",
        "  \n",
        "  Args:\n",
        "    SOURCE_DIR (string): directory path containing the images\n",
        "    CLASS_NAME (array_like): Array of class names\n",
        "    TARGET_SIZE (array_like): Dimension of the images\n",
        "    \n",
        "  Returns:\n",
        "    array_like: Images data\n",
        "    array_like: Images label\n",
        "  \"\"\"\n",
        "\n",
        "  dataset = []\n",
        "  label = []\n",
        "\n",
        "  for _class in CLASS_NAME:\n",
        "    tmp_dataset = []\n",
        "    folder_path = os.path.join(SOURCE_DIR, _class)\n",
        "    for img_file in os.listdir(folder_path):\n",
        "      path = os.path.join(folder_path, img_file)\n",
        "      try:\n",
        "        image=tf.keras.preprocessing.image.load_img(path, color_mode='rgb', \n",
        "              target_size=TARGET_SIZE)\n",
        "      except:\n",
        "        print(f'File {img_file} in {_class} is corrupted')\n",
        "      else:\n",
        "        image=tf.keras.preprocessing.image.load_img(path, color_mode='rgb', \n",
        "            target_size=TARGET_SIZE)\n",
        "        image=np.array(image)\n",
        "        tmp_dataset.append(image)\n",
        "        del image\n",
        "        label.append(_class)\n",
        "    dataset.append(np.asarray(tmp_dataset))\n",
        "    del tmp_dataset\n",
        "  dataset = np.concatenate(dataset, axis=0)\n",
        "  \n",
        "  # Label converter\n",
        "  labels = []\n",
        "  for _label in label:\n",
        "    labels.append(CLASS_NAME.index(_label))\n",
        "    \n",
        "  # One hot encoder for multiple classes\n",
        "  if len(CLASS_NAME) > 2:\n",
        "    labels = tf.keras.utils.to_categorical(labels).astype(int)\n",
        "  del label\n",
        "\n",
        "  return dataset, np.asarray(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d27fcf8",
      "metadata": {},
      "outputs": [],
      "source": [
        "class_name = ['adenocarcinoma', 'squamous-cell-carcinoma', 'large-cell-carcinoma', 'normal']\n",
        "img_size = (160,160)\n",
        "dataset, labels = load_dataset(source_path, class_name, img_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1fdf5af",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Checking dataset and labels shape\n",
        "print(dataset.shape)\n",
        "print(labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5df37a24",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train test split\n",
        "train_data, test_data, label_train, label_test = train_test_split(dataset, labels, train_size=0.9, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d659f6ed",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Checking train, test, and it's label shape\n",
        "print(train_data.shape)\n",
        "print(label_train.shape)\n",
        "print(test_data.shape)\n",
        "print(label_test.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "633f088f",
      "metadata": {},
      "source": [
        "Defining our transfer learning model using MobileNetV2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oDPK8tUB_O9e",
      "metadata": {
        "cellView": "code",
        "id": "oDPK8tUB_O9e",
        "lines_to_next_cell": 2,
        "tags": []
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "  # Define out base model\n",
        "  base_model = tf.keras.applications.MobileNetV2(input_shape=(160, 160, 3),\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')\n",
        "  base_model.trainable = False # Freeze the base model\n",
        "  \n",
        "  # We need to prepocess our input\n",
        "  preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
        "\n",
        "  # Add classifier\n",
        "  global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "  prediction_layer = tf.keras.layers.Dense(4, activation='softmax')\n",
        "\n",
        "  # Let's Combine our model with Functional API\n",
        "  inputs = tf.keras.Input(shape=(160, 160, 3))\n",
        "  x = preprocess_input(inputs)\n",
        "  x = base_model(x, training=False)\n",
        "  x = global_average_layer(x)\n",
        "  x = tf.keras.layers.Dropout(0.1)(x) # Adding the dropout to prevent overfitting\n",
        "  outputs = prediction_layer(x)\n",
        "  model = tf.keras.Model(inputs, outputs)\n",
        "  \n",
        "  # Compile our model\n",
        "  model.compile(loss='categorical_crossentropy', \n",
        "              metrics=['categorical_accuracy'],\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\n",
        "    \n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5qE1G6JB4fMn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qE1G6JB4fMn",
        "outputId": "a545b00a-b997-4276-f364-38165ab7a80a",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Get the untrained model\n",
        "model = create_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5228475b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display model architecture\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46e96c80",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the model\n",
        "# Note that this may take some time.\n",
        "history = model.fit(train_data, label_train,batch_size=64, validation_split=0.1, epochs=50)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "VGsaDMc-GMd4",
      "metadata": {
        "id": "VGsaDMc-GMd4"
      },
      "source": [
        "Once training has finished, you can run the following cell to check the training and validation accuracy achieved at the end of each epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MWZrJN4-65RC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "MWZrJN4-65RC",
        "outputId": "86329302-9faa-4fb2-f56b-d536de4893e1",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Retrieve a list of list results on training and test data\n",
        "# sets for each training epoch\n",
        "acc=history.history['categorical_accuracy']\n",
        "val_acc=history.history['val_categorical_accuracy']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs=range(len(acc)) # Get number of epochs\n",
        "\n",
        "# Plot training and validation accuracy per epoch\n",
        "plt.plot(epochs, acc, 'r', label='acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='val_acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "print(\"\")\n",
        "\n",
        "# Plot training and validation loss per epoch\n",
        "plt.plot(epochs, loss, 'r', label='loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='val_loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "4673048e",
      "metadata": {},
      "source": [
        "Test our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b377bab1",
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_prediction(model, data, label, CLASS_NAME):\n",
        "  \"\"\"\n",
        "  Preview sample images from directories\n",
        "  \n",
        "  Args:\n",
        "    model: trained model\n",
        "    data (array-like): data to predict\n",
        "    label (array-like) : true label of data\n",
        "    CLASS_NAME (array_like): Array of class names\n",
        "    \n",
        "  Returns:\n",
        "    None\n",
        "  \"\"\"\n",
        "\n",
        "  idx = randint(0, label.shape[0]-1)\n",
        "  x = np.expand_dims(data[idx], axis=0)\n",
        "  y_pred = model.predict(x)\n",
        "  y_pred = np.argmax(y_pred)\n",
        "  y = np.argmax(label[idx])\n",
        "  plt.imshow(data[idx])\n",
        "  plt.xlabel(f'Predicted class: {CLASS_NAME[y_pred]}\\nActual class: {CLASS_NAME[y]}')\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eae220ad",
      "metadata": {},
      "outputs": [],
      "source": [
        "make_prediction(model, test_data, label_test, class_name)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "a665b5d41d17b532ea9890333293a1b812fa0b73c9c25c950b3cedf1bebd0438"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
